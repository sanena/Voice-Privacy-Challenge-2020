sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet
sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs
sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls-vctk_test_trials_m_anon
EER: 53.62%
minDCF(p-target=0.01): 1.0000
minDCF(p-target=0.001): 1.0000
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_m, enroll - anonymized, trial - anonymized**
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls_anon-vctk_test_trials_m_anon
EER: 31.11%
minDCF(p-target=0.01): 1.0000
minDCF(p-target=0.001): 1.0000
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_f_common, enroll - original, trial - original**
  compute MFCC: vctk_test_trials_f_common
steps/make_mfcc.sh --nj 12 --cmd run.pl --write-utt2num-frames true data/vctk_test_trials_f_common
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_trials_f_common
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_trials_f_common
fix_data_dir.sh: kept all 346 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_f_common/.backup
  compute VAD: vctk_test_trials_f_common
sid/compute_vad_decision.sh --nj 12 --cmd run.pl data/vctk_test_trials_f_common
Created VAD output for vctk_test_trials_f_common
fix_data_dir.sh: kept all 346 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_f_common/.backup
  compute x-vect: vctk_test_trials_f_common
sid/nnet3/xvector/extract_xvectors.sh --nj 12 --cmd run.pl exp/models/asv_eval/xvect_01709_1 data/vctk_test_trials_f_common exp/models/asv_eval/xvect_01709_1/xvect_vctk_test_trials_f_common
sid/nnet3/xvector/extract_xvectors.sh: using exp/models/asv_eval/xvect_01709_1/extract.config to extract xvectors
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors for data/vctk_test_trials_f_common
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet
sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs
sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls-vctk_test_trials_f_common
EER: 2.89%
minDCF(p-target=0.01): 0.2257
minDCF(p-target=0.001): 0.2543
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_f_common, enroll - original, trial - anonymized**
  compute MFCC: vctk_test_trials_f_common_anon
steps/make_mfcc.sh --nj 12 --cmd run.pl --write-utt2num-frames true data/vctk_test_trials_f_common_anon
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_trials_f_common_anon
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_trials_f_common_anon
fix_data_dir.sh: kept all 346 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_f_common_anon/.backup
  compute VAD: vctk_test_trials_f_common_anon
sid/compute_vad_decision.sh --nj 12 --cmd run.pl data/vctk_test_trials_f_common_anon
Created VAD output for vctk_test_trials_f_common_anon
fix_data_dir.sh: kept all 346 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_f_common_anon/.backup
  compute x-vect: vctk_test_trials_f_common_anon
sid/nnet3/xvector/extract_xvectors.sh --nj 12 --cmd run.pl exp/models/asv_eval/xvect_01709_1 data/vctk_test_trials_f_common_anon exp/models/asv_eval/xvect_01709_1/xvect_vctk_test_trials_f_common_anon
sid/nnet3/xvector/extract_xvectors.sh: using exp/models/asv_eval/xvect_01709_1/extract.config to extract xvectors
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors for data/vctk_test_trials_f_common_anon
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet
sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs
sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls-vctk_test_trials_f_common_anon
EER: 48.27%
minDCF(p-target=0.01): 1.0000
minDCF(p-target=0.001): 1.0000
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_f_common, enroll - anonymized, trial - anonymized**
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls_anon-vctk_test_trials_f_common_anon
EER: 31.5%
minDCF(p-target=0.01): 0.9971
minDCF(p-target=0.001): 0.9971
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_m_common, enroll - original, trial - original**
  compute MFCC: vctk_test_trials_m_common
steps/make_mfcc.sh --nj 12 --cmd run.pl --write-utt2num-frames true data/vctk_test_trials_m_common
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_trials_m_common
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_trials_m_common
fix_data_dir.sh: kept all 354 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_m_common/.backup
  compute VAD: vctk_test_trials_m_common
sid/compute_vad_decision.sh --nj 12 --cmd run.pl data/vctk_test_trials_m_common
Created VAD output for vctk_test_trials_m_common
fix_data_dir.sh: kept all 354 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_m_common/.backup
  compute x-vect: vctk_test_trials_m_common
sid/nnet3/xvector/extract_xvectors.sh --nj 12 --cmd run.pl exp/models/asv_eval/xvect_01709_1 data/vctk_test_trials_m_common exp/models/asv_eval/xvect_01709_1/xvect_vctk_test_trials_m_common
sid/nnet3/xvector/extract_xvectors.sh: using exp/models/asv_eval/xvect_01709_1/extract.config to extract xvectors
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors for data/vctk_test_trials_m_common
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet
sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs
sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls-vctk_test_trials_m_common
EER: 1.13%
minDCF(p-target=0.01): 0.0480
minDCF(p-target=0.001): 0.0480
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_m_common, enroll - original, trial - anonymized**
  compute MFCC: vctk_test_trials_m_common_anon
steps/make_mfcc.sh --nj 12 --cmd run.pl --write-utt2num-frames true data/vctk_test_trials_m_common_anon
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_trials_m_common_anon
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_trials_m_common_anon
fix_data_dir.sh: kept all 354 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_m_common_anon/.backup
  compute VAD: vctk_test_trials_m_common_anon
sid/compute_vad_decision.sh --nj 12 --cmd run.pl data/vctk_test_trials_m_common_anon
Created VAD output for vctk_test_trials_m_common_anon
fix_data_dir.sh: kept all 354 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_m_common_anon/.backup
  compute x-vect: vctk_test_trials_m_common_anon
sid/nnet3/xvector/extract_xvectors.sh --nj 12 --cmd run.pl exp/models/asv_eval/xvect_01709_1 data/vctk_test_trials_m_common_anon exp/models/asv_eval/xvect_01709_1/xvect_vctk_test_trials_m_common_anon
sid/nnet3/xvector/extract_xvectors.sh: using exp/models/asv_eval/xvect_01709_1/extract.config to extract xvectors
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors for data/vctk_test_trials_m_common_anon
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet
sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs
sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls-vctk_test_trials_m_common_anon
EER: 53.11%
minDCF(p-target=0.01): 1.0000
minDCF(p-target=0.001): 1.0000
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_m_common, enroll - anonymized, trial - anonymized**
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls_anon-vctk_test_trials_m_common_anon
EER: 30.79%
minDCF(p-target=0.01): 1.0000
minDCF(p-target=0.001): 1.0000
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'

Stage 12: Making ASR evaluation subsets...
utils/combine_data.sh data/libri_dev_asr data/libri_dev_trials_f data/libri_dev_trials_m
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 1978 utterances.
fix_data_dir.sh: old files are kept in data/libri_dev_asr/.backup
utils/combine_data.sh data/libri_dev_asr_anon data/libri_dev_trials_f_anon data/libri_dev_trials_m_anon
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 1978 utterances.
fix_data_dir.sh: old files are kept in data/libri_dev_asr_anon/.backup
utils/combine_data.sh data/vctk_dev_asr data/vctk_dev_trials_f_all data/vctk_dev_trials_m_all
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 11372 utterances.
fix_data_dir.sh: old files are kept in data/vctk_dev_asr/.backup
utils/combine_data.sh data/vctk_dev_asr_anon data/vctk_dev_trials_f_all_anon data/vctk_dev_trials_m_all_anon
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh [info]: not combining feats.scp as it does not exist
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh [info]: not combining vad.scp as it does not exist
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 11372 utterances.
fix_data_dir.sh: old files are kept in data/vctk_dev_asr_anon/.backup
utils/combine_data.sh data/libri_test_asr data/libri_test_trials_f data/libri_test_trials_m
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 1496 utterances.
fix_data_dir.sh: old files are kept in data/libri_test_asr/.backup
utils/combine_data.sh data/libri_test_asr_anon data/libri_test_trials_f_anon data/libri_test_trials_m_anon
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 1496 utterances.
fix_data_dir.sh: old files are kept in data/libri_test_asr_anon/.backup
utils/combine_data.sh data/vctk_test_asr data/vctk_test_trials_f_all data/vctk_test_trials_m_all
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 11448 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_asr/.backup
utils/combine_data.sh data/vctk_test_asr_anon data/vctk_test_trials_f_all_anon data/vctk_test_trials_m_all_anon
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh [info]: not combining feats.scp as it does not exist
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh [info]: not combining vad.scp as it does not exist
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 11448 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_asr_anon/.backup

Stage 13: Performing intelligibility assessment using ASR decoding on libri...
  compute MFCC: libri_dev_asr
utils/copy_data_dir.sh: copied data from data/libri_dev_asr to data/libri_dev_asr_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_dev_asr_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/libri_dev_asr_hires
steps/make_mfcc.sh: moving data/libri_dev_asr_hires/feats.scp to data/libri_dev_asr_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_dev_asr_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for libri_dev_asr_hires
steps/compute_cmvn_stats.sh data/libri_dev_asr_hires
Succeeded creating CMVN stats for libri_dev_asr_hires
fix_data_dir.sh: kept all 1978 utterances.
fix_data_dir.sh: old files are kept in data/libri_dev_asr_hires/.backup
  compute i-vect: libri_dev_asr
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/libri_dev_asr_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_libri_dev_asr
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_libri_dev_asr using the extractor in exp/models/asr_eval/extractor.
  decoding: libri_dev_asr
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_libri_dev_asr exp/models/asr_eval/graph_tgsmall data/libri_dev_asr_hires exp/models/asr_eval/decode_libri_dev_asr_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_libri_dev_asr_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_dev_asr_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,2,8) and mean=4.3
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_dev_asr_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 5.23 [ 2081 / 39783, 207 ins, 211 del, 1663 sub ] exp/models/asr_eval/decode_libri_dev_asr_tgsmall/wer_12_0.0
  rescoring: libri_dev_asr
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/libri_dev_asr_hires exp/models/asr_eval/decode_libri_dev_asr_tgsmall exp/models/asr_eval/decode_libri_dev_asr_tglarge
%WER 3.83 [ 1525 / 39783, 187 ins, 144 del, 1194 sub ] exp/models/asr_eval/decode_libri_dev_asr_tglarge/wer_13_0.0

Stage 13: Performing intelligibility assessment using ASR decoding on libri...
  compute MFCC: libri_dev_asr_anon
utils/copy_data_dir.sh: copied data from data/libri_dev_asr_anon to data/libri_dev_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_dev_asr_anon_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/libri_dev_asr_anon_hires
steps/make_mfcc.sh: moving data/libri_dev_asr_anon_hires/feats.scp to data/libri_dev_asr_anon_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_dev_asr_anon_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for libri_dev_asr_anon_hires
steps/compute_cmvn_stats.sh data/libri_dev_asr_anon_hires
Succeeded creating CMVN stats for libri_dev_asr_anon_hires
fix_data_dir.sh: kept all 1978 utterances.
fix_data_dir.sh: old files are kept in data/libri_dev_asr_anon_hires/.backup
  compute i-vect: libri_dev_asr_anon
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/libri_dev_asr_anon_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_libri_dev_asr_anon
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_libri_dev_asr_anon using the extractor in exp/models/asr_eval/extractor.
  decoding: libri_dev_asr_anon
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_libri_dev_asr_anon exp/models/asr_eval/graph_tgsmall data/libri_dev_asr_anon_hires exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,3,14) and mean=7.0
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 8.78 [ 3493 / 39783, 302 ins, 434 del, 2757 sub ] exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall/wer_13_0.0
  rescoring: libri_dev_asr_anon
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/libri_dev_asr_anon_hires exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall exp/models/asr_eval/decode_libri_dev_asr_anon_tglarge
%WER 6.38 [ 2538 / 39783, 281 ins, 263 del, 1994 sub ] exp/models/asr_eval/decode_libri_dev_asr_anon_tglarge/wer_13_0.0

Stage 13: Performing intelligibility assessment using ASR decoding on libri...
  compute MFCC: libri_test_asr
utils/copy_data_dir.sh: copied data from data/libri_test_asr to data/libri_test_asr_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_test_asr_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/libri_test_asr_hires
steps/make_mfcc.sh: moving data/libri_test_asr_hires/feats.scp to data/libri_test_asr_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_test_asr_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for libri_test_asr_hires
steps/compute_cmvn_stats.sh data/libri_test_asr_hires
Succeeded creating CMVN stats for libri_test_asr_hires
fix_data_dir.sh: kept all 1496 utterances.
fix_data_dir.sh: old files are kept in data/libri_test_asr_hires/.backup
  compute i-vect: libri_test_asr
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/libri_test_asr_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_libri_test_asr
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_libri_test_asr using the extractor in exp/models/asr_eval/extractor.
  decoding: libri_test_asr
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_libri_test_asr exp/models/asr_eval/graph_tgsmall data/libri_test_asr_hires exp/models/asr_eval/decode_libri_test_asr_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_libri_test_asr_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_test_asr_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,2,8) and mean=4.4
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_test_asr_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 5.56 [ 1950 / 35042, 229 ins, 184 del, 1537 sub ] exp/models/asr_eval/decode_libri_test_asr_tgsmall/wer_12_0.0
  rescoring: libri_test_asr
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/libri_test_asr_hires exp/models/asr_eval/decode_libri_test_asr_tgsmall exp/models/asr_eval/decode_libri_test_asr_tglarge
%WER 4.16 [ 1456 / 35042, 196 ins, 130 del, 1130 sub ] exp/models/asr_eval/decode_libri_test_asr_tglarge/wer_12_0.5

Stage 13: Performing intelligibility assessment using ASR decoding on libri...
  compute MFCC: libri_test_asr_anon
utils/copy_data_dir.sh: copied data from data/libri_test_asr_anon to data/libri_test_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_test_asr_anon_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/libri_test_asr_anon_hires
steps/make_mfcc.sh: moving data/libri_test_asr_anon_hires/feats.scp to data/libri_test_asr_anon_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_test_asr_anon_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for libri_test_asr_anon_hires
steps/compute_cmvn_stats.sh data/libri_test_asr_anon_hires
Succeeded creating CMVN stats for libri_test_asr_anon_hires
fix_data_dir.sh: kept all 1496 utterances.
fix_data_dir.sh: old files are kept in data/libri_test_asr_anon_hires/.backup
  compute i-vect: libri_test_asr_anon
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/libri_test_asr_anon_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_libri_test_asr_anon
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_libri_test_asr_anon using the extractor in exp/models/asr_eval/extractor.
  decoding: libri_test_asr_anon
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_libri_test_asr_anon exp/models/asr_eval/graph_tgsmall data/libri_test_asr_anon_hires exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,3,15) and mean=7.5
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 9.17 [ 3214 / 35042, 270 ins, 426 del, 2518 sub ] exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall/wer_15_0.0
  rescoring: libri_test_asr_anon
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/libri_test_asr_anon_hires exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall exp/models/asr_eval/decode_libri_test_asr_anon_tglarge
%WER 6.69 [ 2344 / 35042, 219 ins, 305 del, 1820 sub ] exp/models/asr_eval/decode_libri_test_asr_anon_tglarge/wer_15_0.5

Stage 13: Performing intelligibility assessment using ASR decoding on vctk...
  compute MFCC: vctk_dev_asr
utils/copy_data_dir.sh: copied data from data/vctk_dev_asr to data/vctk_dev_asr_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_dev_asr_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/vctk_dev_asr_hires
steps/make_mfcc.sh: moving data/vctk_dev_asr_hires/feats.scp to data/vctk_dev_asr_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_dev_asr_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_dev_asr_hires
steps/compute_cmvn_stats.sh data/vctk_dev_asr_hires
Succeeded creating CMVN stats for vctk_dev_asr_hires
fix_data_dir.sh: kept all 11372 utterances.
fix_data_dir.sh: old files are kept in data/vctk_dev_asr_hires/.backup
  compute i-vect: vctk_dev_asr
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/vctk_dev_asr_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_vctk_dev_asr
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_vctk_dev_asr using the extractor in exp/models/asr_eval/extractor.
  decoding: vctk_dev_asr
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_vctk_dev_asr exp/models/asr_eval/graph_tgsmall data/vctk_dev_asr_hires exp/models/asr_eval/decode_vctk_dev_asr_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_vctk_dev_asr_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_dev_asr_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,3,21) and mean=10.0
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_dev_asr_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 14.00 [ 12130 / 86627, 1150 ins, 1870 del, 9110 sub ] exp/models/asr_eval/decode_vctk_dev_asr_tgsmall/wer_15_0.0
  rescoring: vctk_dev_asr
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/vctk_dev_asr_hires exp/models/asr_eval/decode_vctk_dev_asr_tgsmall exp/models/asr_eval/decode_vctk_dev_asr_tglarge
%WER 10.79 [ 9351 / 86627, 995 ins, 1359 del, 6997 sub ] exp/models/asr_eval/decode_vctk_dev_asr_tglarge/wer_14_0.5

Stage 13: Performing intelligibility assessment using ASR decoding on vctk...
  compute MFCC: vctk_dev_asr_anon
utils/copy_data_dir.sh: copied data from data/vctk_dev_asr_anon to data/vctk_dev_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_dev_asr_anon_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/vctk_dev_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_dev_asr_anon_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_dev_asr_anon_hires
steps/compute_cmvn_stats.sh data/vctk_dev_asr_anon_hires
Succeeded creating CMVN stats for vctk_dev_asr_anon_hires
fix_data_dir.sh: kept all 11372 utterances.
fix_data_dir.sh: old files are kept in data/vctk_dev_asr_anon_hires/.backup
  compute i-vect: vctk_dev_asr_anon
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/vctk_dev_asr_anon_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_vctk_dev_asr_anon
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_vctk_dev_asr_anon using the extractor in exp/models/asr_eval/extractor.
  decoding: vctk_dev_asr_anon
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_vctk_dev_asr_anon exp/models/asr_eval/graph_tgsmall data/vctk_dev_asr_anon_hires exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,4,30) and mean=13.2
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 18.90 [ 16374 / 86627, 1479 ins, 2566 del, 12329 sub ] exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall/wer_16_0.0
  rescoring: vctk_dev_asr_anon
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/vctk_dev_asr_anon_hires exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall exp/models/asr_eval/decode_vctk_dev_asr_anon_tglarge
%WER 15.32 [ 13269 / 86627, 1579 ins, 1729 del, 9961 sub ] exp/models/asr_eval/decode_vctk_dev_asr_anon_tglarge/wer_16_0.0

Stage 13: Performing intelligibility assessment using ASR decoding on vctk...
  compute MFCC: vctk_test_asr
utils/copy_data_dir.sh: copied data from data/vctk_test_asr to data/vctk_test_asr_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_asr_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/vctk_test_asr_hires
steps/make_mfcc.sh: moving data/vctk_test_asr_hires/feats.scp to data/vctk_test_asr_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_asr_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_asr_hires
steps/compute_cmvn_stats.sh data/vctk_test_asr_hires
Succeeded creating CMVN stats for vctk_test_asr_hires
fix_data_dir.sh: kept all 11448 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_asr_hires/.backup
  compute i-vect: vctk_test_asr
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/vctk_test_asr_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_vctk_test_asr
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_vctk_test_asr using the extractor in exp/models/asr_eval/extractor.
  decoding: vctk_test_asr
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_vctk_test_asr exp/models/asr_eval/graph_tgsmall data/vctk_test_asr_hires exp/models/asr_eval/decode_vctk_test_asr_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_vctk_test_asr_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_test_asr_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,3,26) and mean=11.4
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_test_asr_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 16.39 [ 14197 / 86642, 1325 ins, 2236 del, 10636 sub ] exp/models/asr_eval/decode_vctk_test_asr_tgsmall/wer_14_0.0
  rescoring: vctk_test_asr
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/vctk_test_asr_hires exp/models/asr_eval/decode_vctk_test_asr_tgsmall exp/models/asr_eval/decode_vctk_test_asr_tglarge
%WER 12.81 [ 11099 / 86642, 1300 ins, 1468 del, 8331 sub ] exp/models/asr_eval/decode_vctk_test_asr_tglarge/wer_14_0.0

Stage 13: Performing intelligibility assessment using ASR decoding on vctk...
  compute MFCC: vctk_test_asr_anon
utils/copy_data_dir.sh: copied data from data/vctk_test_asr_anon to data/vctk_test_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_asr_anon_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/vctk_test_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_asr_anon_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_asr_anon_hires
steps/compute_cmvn_stats.sh data/vctk_test_asr_anon_hires
Succeeded creating CMVN stats for vctk_test_asr_anon_hires
fix_data_dir.sh: kept all 11448 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_asr_anon_hires/.backup
  compute i-vect: vctk_test_asr_anon
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/vctk_test_asr_anon_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_vctk_test_asr_anon
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_vctk_test_asr_anon using the extractor in exp/models/asr_eval/extractor.
  decoding: vctk_test_asr_anon
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_vctk_test_asr_anon exp/models/asr_eval/graph_tgsmall data/vctk_test_asr_anon_hires exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,4,29) and mean=13.0
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 18.90 [ 16379 / 86642, 1490 ins, 2660 del, 12229 sub ] exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall/wer_15_0.0
  rescoring: vctk_test_asr_anon
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/vctk_test_asr_anon_hires exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall exp/models/asr_eval/decode_vctk_test_asr_anon_tglarge
%WER 15.24 [ 13202 / 86642, 1289 ins, 2048 del, 9865 sub ] exp/models/asr_eval/decode_vctk_test_asr_anon_tglarge/wer_14_0.5

Stage 14: Collecting results
ASV-libri_dev_enrolls-libri_dev_trials_f
  EER: 8.807%sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet
sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs
sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls-vctk_test_trials_m_anon
EER: 53.62%
minDCF(p-target=0.01): 1.0000
minDCF(p-target=0.001): 1.0000
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_m, enroll - anonymized, trial - anonymized**
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls_anon-vctk_test_trials_m_anon
EER: 31.11%
minDCF(p-target=0.01): 1.0000
minDCF(p-target=0.001): 1.0000
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_f_common, enroll - original, trial - original**
  compute MFCC: vctk_test_trials_f_common
steps/make_mfcc.sh --nj 12 --cmd run.pl --write-utt2num-frames true data/vctk_test_trials_f_common
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_trials_f_common
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_trials_f_common
fix_data_dir.sh: kept all 346 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_f_common/.backup
  compute VAD: vctk_test_trials_f_common
sid/compute_vad_decision.sh --nj 12 --cmd run.pl data/vctk_test_trials_f_common
Created VAD output for vctk_test_trials_f_common
fix_data_dir.sh: kept all 346 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_f_common/.backup
  compute x-vect: vctk_test_trials_f_common
sid/nnet3/xvector/extract_xvectors.sh --nj 12 --cmd run.pl exp/models/asv_eval/xvect_01709_1 data/vctk_test_trials_f_common exp/models/asv_eval/xvect_01709_1/xvect_vctk_test_trials_f_common
sid/nnet3/xvector/extract_xvectors.sh: using exp/models/asv_eval/xvect_01709_1/extract.config to extract xvectors
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors for data/vctk_test_trials_f_common
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet
sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs
sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls-vctk_test_trials_f_common
EER: 2.89%
minDCF(p-target=0.01): 0.2257
minDCF(p-target=0.001): 0.2543
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_f_common, enroll - original, trial - anonymized**
  compute MFCC: vctk_test_trials_f_common_anon
steps/make_mfcc.sh --nj 12 --cmd run.pl --write-utt2num-frames true data/vctk_test_trials_f_common_anon
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_trials_f_common_anon
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_trials_f_common_anon
fix_data_dir.sh: kept all 346 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_f_common_anon/.backup
  compute VAD: vctk_test_trials_f_common_anon
sid/compute_vad_decision.sh --nj 12 --cmd run.pl data/vctk_test_trials_f_common_anon
Created VAD output for vctk_test_trials_f_common_anon
fix_data_dir.sh: kept all 346 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_f_common_anon/.backup
  compute x-vect: vctk_test_trials_f_common_anon
sid/nnet3/xvector/extract_xvectors.sh --nj 12 --cmd run.pl exp/models/asv_eval/xvect_01709_1 data/vctk_test_trials_f_common_anon exp/models/asv_eval/xvect_01709_1/xvect_vctk_test_trials_f_common_anon
sid/nnet3/xvector/extract_xvectors.sh: using exp/models/asv_eval/xvect_01709_1/extract.config to extract xvectors
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors for data/vctk_test_trials_f_common_anon
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet
sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs
sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls-vctk_test_trials_f_common_anon
EER: 48.27%
minDCF(p-target=0.01): 1.0000
minDCF(p-target=0.001): 1.0000
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_f_common, enroll - anonymized, trial - anonymized**
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls_anon-vctk_test_trials_f_common_anon
EER: 31.5%
minDCF(p-target=0.01): 0.9971
minDCF(p-target=0.001): 0.9971
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_m_common, enroll - original, trial - original**
  compute MFCC: vctk_test_trials_m_common
steps/make_mfcc.sh --nj 12 --cmd run.pl --write-utt2num-frames true data/vctk_test_trials_m_common
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_trials_m_common
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_trials_m_common
fix_data_dir.sh: kept all 354 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_m_common/.backup
  compute VAD: vctk_test_trials_m_common
sid/compute_vad_decision.sh --nj 12 --cmd run.pl data/vctk_test_trials_m_common
Created VAD output for vctk_test_trials_m_common
fix_data_dir.sh: kept all 354 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_m_common/.backup
  compute x-vect: vctk_test_trials_m_common
sid/nnet3/xvector/extract_xvectors.sh --nj 12 --cmd run.pl exp/models/asv_eval/xvect_01709_1 data/vctk_test_trials_m_common exp/models/asv_eval/xvect_01709_1/xvect_vctk_test_trials_m_common
sid/nnet3/xvector/extract_xvectors.sh: using exp/models/asv_eval/xvect_01709_1/extract.config to extract xvectors
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors for data/vctk_test_trials_m_common
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet
sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs
sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls-vctk_test_trials_m_common
EER: 1.13%
minDCF(p-target=0.01): 0.0480
minDCF(p-target=0.001): 0.0480
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_m_common, enroll - original, trial - anonymized**
  compute MFCC: vctk_test_trials_m_common_anon
steps/make_mfcc.sh --nj 12 --cmd run.pl --write-utt2num-frames true data/vctk_test_trials_m_common_anon
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_trials_m_common_anon
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_trials_m_common_anon
fix_data_dir.sh: kept all 354 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_m_common_anon/.backup
  compute VAD: vctk_test_trials_m_common_anon
sid/compute_vad_decision.sh --nj 12 --cmd run.pl data/vctk_test_trials_m_common_anon
Created VAD output for vctk_test_trials_m_common_anon
fix_data_dir.sh: kept all 354 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_m_common_anon/.backup
  compute x-vect: vctk_test_trials_m_common_anon
sid/nnet3/xvector/extract_xvectors.sh --nj 12 --cmd run.pl exp/models/asv_eval/xvect_01709_1 data/vctk_test_trials_m_common_anon exp/models/asv_eval/xvect_01709_1/xvect_vctk_test_trials_m_common_anon
sid/nnet3/xvector/extract_xvectors.sh: using exp/models/asv_eval/xvect_01709_1/extract.config to extract xvectors
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors for data/vctk_test_trials_m_common_anon
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet
sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs
sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls-vctk_test_trials_m_common_anon
EER: 53.11%
minDCF(p-target=0.01): 1.0000
minDCF(p-target=0.001): 1.0000
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_m_common, enroll - anonymized, trial - anonymized**
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls_anon-vctk_test_trials_m_common_anon
EER: 30.79%
minDCF(p-target=0.01): 1.0000
minDCF(p-target=0.001): 1.0000
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'

Stage 12: Making ASR evaluation subsets...
utils/combine_data.sh data/libri_dev_asr data/libri_dev_trials_f data/libri_dev_trials_m
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 1978 utterances.
fix_data_dir.sh: old files are kept in data/libri_dev_asr/.backup
utils/combine_data.sh data/libri_dev_asr_anon data/libri_dev_trials_f_anon data/libri_dev_trials_m_anon
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 1978 utterances.
fix_data_dir.sh: old files are kept in data/libri_dev_asr_anon/.backup
utils/combine_data.sh data/vctk_dev_asr data/vctk_dev_trials_f_all data/vctk_dev_trials_m_all
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 11372 utterances.
fix_data_dir.sh: old files are kept in data/vctk_dev_asr/.backup
utils/combine_data.sh data/vctk_dev_asr_anon data/vctk_dev_trials_f_all_anon data/vctk_dev_trials_m_all_anon
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh [info]: not combining feats.scp as it does not exist
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh [info]: not combining vad.scp as it does not exist
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 11372 utterances.
fix_data_dir.sh: old files are kept in data/vctk_dev_asr_anon/.backup
utils/combine_data.sh data/libri_test_asr data/libri_test_trials_f data/libri_test_trials_m
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 1496 utterances.
fix_data_dir.sh: old files are kept in data/libri_test_asr/.backup
utils/combine_data.sh data/libri_test_asr_anon data/libri_test_trials_f_anon data/libri_test_trials_m_anon
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 1496 utterances.
fix_data_dir.sh: old files are kept in data/libri_test_asr_anon/.backup
utils/combine_data.sh data/vctk_test_asr data/vctk_test_trials_f_all data/vctk_test_trials_m_all
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 11448 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_asr/.backup
utils/combine_data.sh data/vctk_test_asr_anon data/vctk_test_trials_f_all_anon data/vctk_test_trials_m_all_anon
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh [info]: not combining feats.scp as it does not exist
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh [info]: not combining vad.scp as it does not exist
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 11448 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_asr_anon/.backup

Stage 13: Performing intelligibility assessment using ASR decoding on libri...
  compute MFCC: libri_dev_asr
utils/copy_data_dir.sh: copied data from data/libri_dev_asr to data/libri_dev_asr_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_dev_asr_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/libri_dev_asr_hires
steps/make_mfcc.sh: moving data/libri_dev_asr_hires/feats.scp to data/libri_dev_asr_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_dev_asr_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for libri_dev_asr_hires
steps/compute_cmvn_stats.sh data/libri_dev_asr_hires
Succeeded creating CMVN stats for libri_dev_asr_hires
fix_data_dir.sh: kept all 1978 utterances.
fix_data_dir.sh: old files are kept in data/libri_dev_asr_hires/.backup
  compute i-vect: libri_dev_asr
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/libri_dev_asr_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_libri_dev_asr
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_libri_dev_asr using the extractor in exp/models/asr_eval/extractor.
  decoding: libri_dev_asr
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_libri_dev_asr exp/models/asr_eval/graph_tgsmall data/libri_dev_asr_hires exp/models/asr_eval/decode_libri_dev_asr_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_libri_dev_asr_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_dev_asr_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,2,8) and mean=4.3
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_dev_asr_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 5.23 [ 2081 / 39783, 207 ins, 211 del, 1663 sub ] exp/models/asr_eval/decode_libri_dev_asr_tgsmall/wer_12_0.0
  rescoring: libri_dev_asr
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/libri_dev_asr_hires exp/models/asr_eval/decode_libri_dev_asr_tgsmall exp/models/asr_eval/decode_libri_dev_asr_tglarge
%WER 3.83 [ 1525 / 39783, 187 ins, 144 del, 1194 sub ] exp/models/asr_eval/decode_libri_dev_asr_tglarge/wer_13_0.0

Stage 13: Performing intelligibility assessment using ASR decoding on libri...
  compute MFCC: libri_dev_asr_anon
utils/copy_data_dir.sh: copied data from data/libri_dev_asr_anon to data/libri_dev_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_dev_asr_anon_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/libri_dev_asr_anon_hires
steps/make_mfcc.sh: moving data/libri_dev_asr_anon_hires/feats.scp to data/libri_dev_asr_anon_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_dev_asr_anon_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for libri_dev_asr_anon_hires
steps/compute_cmvn_stats.sh data/libri_dev_asr_anon_hires
Succeeded creating CMVN stats for libri_dev_asr_anon_hires
fix_data_dir.sh: kept all 1978 utterances.
fix_data_dir.sh: old files are kept in data/libri_dev_asr_anon_hires/.backup
  compute i-vect: libri_dev_asr_anon
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/libri_dev_asr_anon_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_libri_dev_asr_anon
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_libri_dev_asr_anon using the extractor in exp/models/asr_eval/extractor.
  decoding: libri_dev_asr_anon
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_libri_dev_asr_anon exp/models/asr_eval/graph_tgsmall data/libri_dev_asr_anon_hires exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,3,14) and mean=7.0
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 8.78 [ 3493 / 39783, 302 ins, 434 del, 2757 sub ] exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall/wer_13_0.0
  rescoring: libri_dev_asr_anon
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/libri_dev_asr_anon_hires exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall exp/models/asr_eval/decode_libri_dev_asr_anon_tglarge
%WER 6.38 [ 2538 / 39783, 281 ins, 263 del, 1994 sub ] exp/models/asr_eval/decode_libri_dev_asr_anon_tglarge/wer_13_0.0

Stage 13: Performing intelligibility assessment using ASR decoding on libri...
  compute MFCC: libri_test_asr
utils/copy_data_dir.sh: copied data from data/libri_test_asr to data/libri_test_asr_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_test_asr_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/libri_test_asr_hires
steps/make_mfcc.sh: moving data/libri_test_asr_hires/feats.scp to data/libri_test_asr_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_test_asr_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for libri_test_asr_hires
steps/compute_cmvn_stats.sh data/libri_test_asr_hires
Succeeded creating CMVN stats for libri_test_asr_hires
fix_data_dir.sh: kept all 1496 utterances.
fix_data_dir.sh: old files are kept in data/libri_test_asr_hires/.backup
  compute i-vect: libri_test_asr
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/libri_test_asr_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_libri_test_asr
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_libri_test_asr using the extractor in exp/models/asr_eval/extractor.
  decoding: libri_test_asr
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_libri_test_asr exp/models/asr_eval/graph_tgsmall data/libri_test_asr_hires exp/models/asr_eval/decode_libri_test_asr_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_libri_test_asr_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_test_asr_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,2,8) and mean=4.4
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_test_asr_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 5.56 [ 1950 / 35042, 229 ins, 184 del, 1537 sub ] exp/models/asr_eval/decode_libri_test_asr_tgsmall/wer_12_0.0
  rescoring: libri_test_asr
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/libri_test_asr_hires exp/models/asr_eval/decode_libri_test_asr_tgsmall exp/models/asr_eval/decode_libri_test_asr_tglarge
%WER 4.16 [ 1456 / 35042, 196 ins, 130 del, 1130 sub ] exp/models/asr_eval/decode_libri_test_asr_tglarge/wer_12_0.5

Stage 13: Performing intelligibility assessment using ASR decoding on libri...
  compute MFCC: libri_test_asr_anon
utils/copy_data_dir.sh: copied data from data/libri_test_asr_anon to data/libri_test_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_test_asr_anon_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/libri_test_asr_anon_hires
steps/make_mfcc.sh: moving data/libri_test_asr_anon_hires/feats.scp to data/libri_test_asr_anon_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_test_asr_anon_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for libri_test_asr_anon_hires
steps/compute_cmvn_stats.sh data/libri_test_asr_anon_hires
Succeeded creating CMVN stats for libri_test_asr_anon_hires
fix_data_dir.sh: kept all 1496 utterances.
fix_data_dir.sh: old files are kept in data/libri_test_asr_anon_hires/.backup
  compute i-vect: libri_test_asr_anon
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/libri_test_asr_anon_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_libri_test_asr_anon
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_libri_test_asr_anon using the extractor in exp/models/asr_eval/extractor.
  decoding: libri_test_asr_anon
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_libri_test_asr_anon exp/models/asr_eval/graph_tgsmall data/libri_test_asr_anon_hires exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,3,15) and mean=7.5
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 9.17 [ 3214 / 35042, 270 ins, 426 del, 2518 sub ] exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall/wer_15_0.0
  rescoring: libri_test_asr_anon
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/libri_test_asr_anon_hires exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall exp/models/asr_eval/decode_libri_test_asr_anon_tglarge
%WER 6.69 [ 2344 / 35042, 219 ins, 305 del, 1820 sub ] exp/models/asr_eval/decode_libri_test_asr_anon_tglarge/wer_15_0.5

Stage 13: Performing intelligibility assessment using ASR decoding on vctk...
  compute MFCC: vctk_dev_asr
utils/copy_data_dir.sh: copied data from data/vctk_dev_asr to data/vctk_dev_asr_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_dev_asr_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/vctk_dev_asr_hires
steps/make_mfcc.sh: moving data/vctk_dev_asr_hires/feats.scp to data/vctk_dev_asr_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_dev_asr_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_dev_asr_hires
steps/compute_cmvn_stats.sh data/vctk_dev_asr_hires
Succeeded creating CMVN stats for vctk_dev_asr_hires
fix_data_dir.sh: kept all 11372 utterances.
fix_data_dir.sh: old files are kept in data/vctk_dev_asr_hires/.backup
  compute i-vect: vctk_dev_asr
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/vctk_dev_asr_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_vctk_dev_asr
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_vctk_dev_asr using the extractor in exp/models/asr_eval/extractor.
  decoding: vctk_dev_asr
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_vctk_dev_asr exp/models/asr_eval/graph_tgsmall data/vctk_dev_asr_hires exp/models/asr_eval/decode_vctk_dev_asr_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_vctk_dev_asr_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_dev_asr_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,3,21) and mean=10.0
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_dev_asr_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 14.00 [ 12130 / 86627, 1150 ins, 1870 del, 9110 sub ] exp/models/asr_eval/decode_vctk_dev_asr_tgsmall/wer_15_0.0
  rescoring: vctk_dev_asr
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/vctk_dev_asr_hires exp/models/asr_eval/decode_vctk_dev_asr_tgsmall exp/models/asr_eval/decode_vctk_dev_asr_tglarge
%WER 10.79 [ 9351 / 86627, 995 ins, 1359 del, 6997 sub ] exp/models/asr_eval/decode_vctk_dev_asr_tglarge/wer_14_0.5

Stage 13: Performing intelligibility assessment using ASR decoding on vctk...
  compute MFCC: vctk_dev_asr_anon
utils/copy_data_dir.sh: copied data from data/vctk_dev_asr_anon to data/vctk_dev_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_dev_asr_anon_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/vctk_dev_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_dev_asr_anon_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_dev_asr_anon_hires
steps/compute_cmvn_stats.sh data/vctk_dev_asr_anon_hires
Succeeded creating CMVN stats for vctk_dev_asr_anon_hires
fix_data_dir.sh: kept all 11372 utterances.
fix_data_dir.sh: old files are kept in data/vctk_dev_asr_anon_hires/.backup
  compute i-vect: vctk_dev_asr_anon
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/vctk_dev_asr_anon_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_vctk_dev_asr_anon
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_vctk_dev_asr_anon using the extractor in exp/models/asr_eval/extractor.
  decoding: vctk_dev_asr_anon
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_vctk_dev_asr_anon exp/models/asr_eval/graph_tgsmall data/vctk_dev_asr_anon_hires exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,4,30) and mean=13.2
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 18.90 [ 16374 / 86627, 1479 ins, 2566 del, 12329 sub ] exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall/wer_16_0.0
  rescoring: vctk_dev_asr_anon
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/vctk_dev_asr_anon_hires exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall exp/models/asr_eval/decode_vctk_dev_asr_anon_tglarge
%WER 15.32 [ 13269 / 86627, 1579 ins, 1729 del, 9961 sub ] exp/models/asr_eval/decode_vctk_dev_asr_anon_tglarge/wer_16_0.0

Stage 13: Performing intelligibility assessment using ASR decoding on vctk...
  compute MFCC: vctk_test_asr
utils/copy_data_dir.sh: copied data from data/vctk_test_asr to data/vctk_test_asr_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_asr_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/vctk_test_asr_hires
steps/make_mfcc.sh: moving data/vctk_test_asr_hires/feats.scp to data/vctk_test_asr_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_asr_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_asr_hires
steps/compute_cmvn_stats.sh data/vctk_test_asr_hires
Succeeded creating CMVN stats for vctk_test_asr_hires
fix_data_dir.sh: kept all 11448 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_asr_hires/.backup
  compute i-vect: vctk_test_asr
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/vctk_test_asr_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_vctk_test_asr
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_vctk_test_asr using the extractor in exp/models/asr_eval/extractor.
  decoding: vctk_test_asr
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_vctk_test_asr exp/models/asr_eval/graph_tgsmall data/vctk_test_asr_hires exp/models/asr_eval/decode_vctk_test_asr_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_vctk_test_asr_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_test_asr_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,3,26) and mean=11.4
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_test_asr_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 16.39 [ 14197 / 86642, 1325 ins, 2236 del, 10636 sub ] exp/models/asr_eval/decode_vctk_test_asr_tgsmall/wer_14_0.0
  rescoring: vctk_test_asr
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/vctk_test_asr_hires exp/models/asr_eval/decode_vctk_test_asr_tgsmall exp/models/asr_eval/decode_vctk_test_asr_tglarge
%WER 12.81 [ 11099 / 86642, 1300 ins, 1468 del, 8331 sub ] exp/models/asr_eval/decode_vctk_test_asr_tglarge/wer_14_0.0

Stage 13: Performing intelligibility assessment using ASR decoding on vctk...
  compute MFCC: vctk_test_asr_anon
utils/copy_data_dir.sh: copied data from data/vctk_test_asr_anon to data/vctk_test_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_asr_anon_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/vctk_test_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_asr_anon_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_asr_anon_hires
steps/compute_cmvn_stats.sh data/vctk_test_asr_anon_hires
Succeeded creating CMVN stats for vctk_test_asr_anon_hires
fix_data_dir.sh: kept all 11448 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_asr_anon_hires/.backup
  compute i-vect: vctk_test_asr_anon
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/vctk_test_asr_anon_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_vctk_test_asr_anon
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_vctk_test_asr_anon using the extractor in exp/models/asr_eval/extractor.
  decoding: vctk_test_asr_anon
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_vctk_test_asr_anon exp/models/asr_eval/graph_tgsmall data/vctk_test_asr_anon_hires exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,4,29) and mean=13.0
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 18.90 [ 16379 / 86642, 1490 ins, 2660 del, 12229 sub ] exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall/wer_15_0.0
  rescoring: vctk_test_asr_anon
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/vctk_test_asr_anon_hires exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall exp/models/asr_eval/decode_vctk_test_asr_anon_tglarge
%WER 15.24 [ 13202 / 86642, 1289 ins, 2048 del, 9865 sub ] exp/models/asr_eval/decode_vctk_test_asr_anon_tglarge/wer_14_0.5

Stage 14: Collecting results
ASV-libri_dev_enrolls-libri_dev_trials_f
  EER: 8.807%sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet
sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs
sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls-vctk_test_trials_m_anon
EER: 53.62%
minDCF(p-target=0.01): 1.0000
minDCF(p-target=0.001): 1.0000
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_m, enroll - anonymized, trial - anonymized**
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls_anon-vctk_test_trials_m_anon
EER: 31.11%
minDCF(p-target=0.01): 1.0000
minDCF(p-target=0.001): 1.0000
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_f_common, enroll - original, trial - original**
  compute MFCC: vctk_test_trials_f_common
steps/make_mfcc.sh --nj 12 --cmd run.pl --write-utt2num-frames true data/vctk_test_trials_f_common
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_trials_f_common
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_trials_f_common
fix_data_dir.sh: kept all 346 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_f_common/.backup
  compute VAD: vctk_test_trials_f_common
sid/compute_vad_decision.sh --nj 12 --cmd run.pl data/vctk_test_trials_f_common
Created VAD output for vctk_test_trials_f_common
fix_data_dir.sh: kept all 346 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_f_common/.backup
  compute x-vect: vctk_test_trials_f_common
sid/nnet3/xvector/extract_xvectors.sh --nj 12 --cmd run.pl exp/models/asv_eval/xvect_01709_1 data/vctk_test_trials_f_common exp/models/asv_eval/xvect_01709_1/xvect_vctk_test_trials_f_common
sid/nnet3/xvector/extract_xvectors.sh: using exp/models/asv_eval/xvect_01709_1/extract.config to extract xvectors
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors for data/vctk_test_trials_f_common
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet
sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs
sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls-vctk_test_trials_f_common
EER: 2.89%
minDCF(p-target=0.01): 0.2257
minDCF(p-target=0.001): 0.2543
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_f_common, enroll - original, trial - anonymized**
  compute MFCC: vctk_test_trials_f_common_anon
steps/make_mfcc.sh --nj 12 --cmd run.pl --write-utt2num-frames true data/vctk_test_trials_f_common_anon
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_trials_f_common_anon
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_trials_f_common_anon
fix_data_dir.sh: kept all 346 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_f_common_anon/.backup
  compute VAD: vctk_test_trials_f_common_anon
sid/compute_vad_decision.sh --nj 12 --cmd run.pl data/vctk_test_trials_f_common_anon
Created VAD output for vctk_test_trials_f_common_anon
fix_data_dir.sh: kept all 346 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_f_common_anon/.backup
  compute x-vect: vctk_test_trials_f_common_anon
sid/nnet3/xvector/extract_xvectors.sh --nj 12 --cmd run.pl exp/models/asv_eval/xvect_01709_1 data/vctk_test_trials_f_common_anon exp/models/asv_eval/xvect_01709_1/xvect_vctk_test_trials_f_common_anon
sid/nnet3/xvector/extract_xvectors.sh: using exp/models/asv_eval/xvect_01709_1/extract.config to extract xvectors
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors for data/vctk_test_trials_f_common_anon
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet
sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs
sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls-vctk_test_trials_f_common_anon
EER: 48.27%
minDCF(p-target=0.01): 1.0000
minDCF(p-target=0.001): 1.0000
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_f_common, enroll - anonymized, trial - anonymized**
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls_anon-vctk_test_trials_f_common_anon
EER: 31.5%
minDCF(p-target=0.01): 0.9971
minDCF(p-target=0.001): 0.9971
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_m_common, enroll - original, trial - original**
  compute MFCC: vctk_test_trials_m_common
steps/make_mfcc.sh --nj 12 --cmd run.pl --write-utt2num-frames true data/vctk_test_trials_m_common
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_trials_m_common
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_trials_m_common
fix_data_dir.sh: kept all 354 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_m_common/.backup
  compute VAD: vctk_test_trials_m_common
sid/compute_vad_decision.sh --nj 12 --cmd run.pl data/vctk_test_trials_m_common
Created VAD output for vctk_test_trials_m_common
fix_data_dir.sh: kept all 354 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_m_common/.backup
  compute x-vect: vctk_test_trials_m_common
sid/nnet3/xvector/extract_xvectors.sh --nj 12 --cmd run.pl exp/models/asv_eval/xvect_01709_1 data/vctk_test_trials_m_common exp/models/asv_eval/xvect_01709_1/xvect_vctk_test_trials_m_common
sid/nnet3/xvector/extract_xvectors.sh: using exp/models/asv_eval/xvect_01709_1/extract.config to extract xvectors
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors for data/vctk_test_trials_m_common
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet
sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs
sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls-vctk_test_trials_m_common
EER: 1.13%
minDCF(p-target=0.01): 0.0480
minDCF(p-target=0.001): 0.0480
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_m_common, enroll - original, trial - anonymized**
  compute MFCC: vctk_test_trials_m_common_anon
steps/make_mfcc.sh --nj 12 --cmd run.pl --write-utt2num-frames true data/vctk_test_trials_m_common_anon
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_trials_m_common_anon
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_trials_m_common_anon
fix_data_dir.sh: kept all 354 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_m_common_anon/.backup
  compute VAD: vctk_test_trials_m_common_anon
sid/compute_vad_decision.sh --nj 12 --cmd run.pl data/vctk_test_trials_m_common_anon
Created VAD output for vctk_test_trials_m_common_anon
fix_data_dir.sh: kept all 354 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_trials_m_common_anon/.backup
  compute x-vect: vctk_test_trials_m_common_anon
sid/nnet3/xvector/extract_xvectors.sh --nj 12 --cmd run.pl exp/models/asv_eval/xvect_01709_1 data/vctk_test_trials_m_common_anon exp/models/asv_eval/xvect_01709_1/xvect_vctk_test_trials_m_common_anon
sid/nnet3/xvector/extract_xvectors.sh: using exp/models/asv_eval/xvect_01709_1/extract.config to extract xvectors
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors for data/vctk_test_trials_m_common_anon
sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet
sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs
sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls-vctk_test_trials_m_common_anon
EER: 53.11%
minDCF(p-target=0.01): 1.0000
minDCF(p-target=0.001): 1.0000
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'
**ASV: vctk_test_trials_m_common, enroll - anonymized, trial - anonymized**
  ASV scoring: exp/results-2023-07-27-19-52-01/ASV-vctk_test_enrolls_anon-vctk_test_trials_m_common_anon
EER: 30.79%
minDCF(p-target=0.01): 1.0000
minDCF(p-target=0.001): 1.0000
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../cllr/compute_cllr.py", line 3, in <module>
    import pandas
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 31, in <module>
    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 3, in <module>
    from .tslibs import (
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 3, in <module>
    from .conversion import localize_pydatetime, normalize_date
  File "pandas/_libs/tslibs/c_timestamp.pxd", line 7, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/c_timestamp.pyx", line 1, in init pandas._libs.tslibs.c_timestamp
  File "pandas/_libs/tslibs/timezones.pyx", line 4, in init pandas._libs.tslibs.timezones
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/__init__.py", line 2, in <module>
    from .tz import *
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/dateutil/tz/tz.py", line 19, in <module>
    import six
ModuleNotFoundError: No module named 'six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "local/scoring/linkability/compute_linkability.py", line 1, in <module>
    from performance import linkability, draw_scores
  File "/data/yh/Voice-Privacy-Challenge-2020/anonymization_metrics/performance.py", line 4, in <module>
    import pandas as pd
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/pandas/__init__.py", line 36, in <module>
    f"C extension: {module} not built. If you want to import "
ImportError: C extension: No module named 'six' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.
Traceback (most recent call last):
  File "../zebra/zero_evidence.py", line 2, in <module>
    from matplotlib.pyplot import show, legend
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/__init__.py", line 107, in <module>
    from . import cbook, rcsetup
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/matplotlib/rcsetup.py", line 32, in <module>
    from cycler import Cycler, cycler as ccycler
  File "/home/yh/.conda/envs/vp/lib/python3.7/site-packages/cycler.py", line 46, in <module>
    import six
ModuleNotFoundError: No module named 'six'

Stage 12: Making ASR evaluation subsets...
utils/combine_data.sh data/libri_dev_asr data/libri_dev_trials_f data/libri_dev_trials_m
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 1978 utterances.
fix_data_dir.sh: old files are kept in data/libri_dev_asr/.backup
utils/combine_data.sh data/libri_dev_asr_anon data/libri_dev_trials_f_anon data/libri_dev_trials_m_anon
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 1978 utterances.
fix_data_dir.sh: old files are kept in data/libri_dev_asr_anon/.backup
utils/combine_data.sh data/vctk_dev_asr data/vctk_dev_trials_f_all data/vctk_dev_trials_m_all
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 11372 utterances.
fix_data_dir.sh: old files are kept in data/vctk_dev_asr/.backup
utils/combine_data.sh data/vctk_dev_asr_anon data/vctk_dev_trials_f_all_anon data/vctk_dev_trials_m_all_anon
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh [info]: not combining feats.scp as it does not exist
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh [info]: not combining vad.scp as it does not exist
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 11372 utterances.
fix_data_dir.sh: old files are kept in data/vctk_dev_asr_anon/.backup
utils/combine_data.sh data/libri_test_asr data/libri_test_trials_f data/libri_test_trials_m
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 1496 utterances.
fix_data_dir.sh: old files are kept in data/libri_test_asr/.backup
utils/combine_data.sh data/libri_test_asr_anon data/libri_test_trials_f_anon data/libri_test_trials_m_anon
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 1496 utterances.
fix_data_dir.sh: old files are kept in data/libri_test_asr_anon/.backup
utils/combine_data.sh data/vctk_test_asr data/vctk_test_trials_f_all data/vctk_test_trials_m_all
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh: combined feats.scp
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh: combined vad.scp
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 11448 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_asr/.backup
utils/combine_data.sh data/vctk_test_asr_anon data/vctk_test_trials_f_all_anon data/vctk_test_trials_m_all_anon
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh: combined utt2dur
utils/combine_data.sh: combined utt2num_frames
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh [info]: not combining feats.scp as it does not exist
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh [info]: not combining vad.scp as it does not exist
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 11448 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_asr_anon/.backup

Stage 13: Performing intelligibility assessment using ASR decoding on libri...
  compute MFCC: libri_dev_asr
utils/copy_data_dir.sh: copied data from data/libri_dev_asr to data/libri_dev_asr_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_dev_asr_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/libri_dev_asr_hires
steps/make_mfcc.sh: moving data/libri_dev_asr_hires/feats.scp to data/libri_dev_asr_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_dev_asr_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for libri_dev_asr_hires
steps/compute_cmvn_stats.sh data/libri_dev_asr_hires
Succeeded creating CMVN stats for libri_dev_asr_hires
fix_data_dir.sh: kept all 1978 utterances.
fix_data_dir.sh: old files are kept in data/libri_dev_asr_hires/.backup
  compute i-vect: libri_dev_asr
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/libri_dev_asr_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_libri_dev_asr
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_libri_dev_asr using the extractor in exp/models/asr_eval/extractor.
  decoding: libri_dev_asr
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_libri_dev_asr exp/models/asr_eval/graph_tgsmall data/libri_dev_asr_hires exp/models/asr_eval/decode_libri_dev_asr_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_libri_dev_asr_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_dev_asr_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,2,8) and mean=4.3
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_dev_asr_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 5.23 [ 2081 / 39783, 207 ins, 211 del, 1663 sub ] exp/models/asr_eval/decode_libri_dev_asr_tgsmall/wer_12_0.0
  rescoring: libri_dev_asr
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/libri_dev_asr_hires exp/models/asr_eval/decode_libri_dev_asr_tgsmall exp/models/asr_eval/decode_libri_dev_asr_tglarge
%WER 3.83 [ 1525 / 39783, 187 ins, 144 del, 1194 sub ] exp/models/asr_eval/decode_libri_dev_asr_tglarge/wer_13_0.0

Stage 13: Performing intelligibility assessment using ASR decoding on libri...
  compute MFCC: libri_dev_asr_anon
utils/copy_data_dir.sh: copied data from data/libri_dev_asr_anon to data/libri_dev_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_dev_asr_anon_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/libri_dev_asr_anon_hires
steps/make_mfcc.sh: moving data/libri_dev_asr_anon_hires/feats.scp to data/libri_dev_asr_anon_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_dev_asr_anon_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for libri_dev_asr_anon_hires
steps/compute_cmvn_stats.sh data/libri_dev_asr_anon_hires
Succeeded creating CMVN stats for libri_dev_asr_anon_hires
fix_data_dir.sh: kept all 1978 utterances.
fix_data_dir.sh: old files are kept in data/libri_dev_asr_anon_hires/.backup
  compute i-vect: libri_dev_asr_anon
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/libri_dev_asr_anon_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_libri_dev_asr_anon
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_libri_dev_asr_anon using the extractor in exp/models/asr_eval/extractor.
  decoding: libri_dev_asr_anon
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_libri_dev_asr_anon exp/models/asr_eval/graph_tgsmall data/libri_dev_asr_anon_hires exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,3,14) and mean=7.0
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 8.78 [ 3493 / 39783, 302 ins, 434 del, 2757 sub ] exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall/wer_13_0.0
  rescoring: libri_dev_asr_anon
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/libri_dev_asr_anon_hires exp/models/asr_eval/decode_libri_dev_asr_anon_tgsmall exp/models/asr_eval/decode_libri_dev_asr_anon_tglarge
%WER 6.38 [ 2538 / 39783, 281 ins, 263 del, 1994 sub ] exp/models/asr_eval/decode_libri_dev_asr_anon_tglarge/wer_13_0.0

Stage 13: Performing intelligibility assessment using ASR decoding on libri...
  compute MFCC: libri_test_asr
utils/copy_data_dir.sh: copied data from data/libri_test_asr to data/libri_test_asr_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_test_asr_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/libri_test_asr_hires
steps/make_mfcc.sh: moving data/libri_test_asr_hires/feats.scp to data/libri_test_asr_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_test_asr_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for libri_test_asr_hires
steps/compute_cmvn_stats.sh data/libri_test_asr_hires
Succeeded creating CMVN stats for libri_test_asr_hires
fix_data_dir.sh: kept all 1496 utterances.
fix_data_dir.sh: old files are kept in data/libri_test_asr_hires/.backup
  compute i-vect: libri_test_asr
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/libri_test_asr_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_libri_test_asr
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_libri_test_asr using the extractor in exp/models/asr_eval/extractor.
  decoding: libri_test_asr
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_libri_test_asr exp/models/asr_eval/graph_tgsmall data/libri_test_asr_hires exp/models/asr_eval/decode_libri_test_asr_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_libri_test_asr_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_test_asr_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,2,8) and mean=4.4
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_test_asr_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 5.56 [ 1950 / 35042, 229 ins, 184 del, 1537 sub ] exp/models/asr_eval/decode_libri_test_asr_tgsmall/wer_12_0.0
  rescoring: libri_test_asr
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/libri_test_asr_hires exp/models/asr_eval/decode_libri_test_asr_tgsmall exp/models/asr_eval/decode_libri_test_asr_tglarge
%WER 4.16 [ 1456 / 35042, 196 ins, 130 del, 1130 sub ] exp/models/asr_eval/decode_libri_test_asr_tglarge/wer_12_0.5

Stage 13: Performing intelligibility assessment using ASR decoding on libri...
  compute MFCC: libri_test_asr_anon
utils/copy_data_dir.sh: copied data from data/libri_test_asr_anon to data/libri_test_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_test_asr_anon_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/libri_test_asr_anon_hires
steps/make_mfcc.sh: moving data/libri_test_asr_anon_hires/feats.scp to data/libri_test_asr_anon_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/libri_test_asr_anon_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for libri_test_asr_anon_hires
steps/compute_cmvn_stats.sh data/libri_test_asr_anon_hires
Succeeded creating CMVN stats for libri_test_asr_anon_hires
fix_data_dir.sh: kept all 1496 utterances.
fix_data_dir.sh: old files are kept in data/libri_test_asr_anon_hires/.backup
  compute i-vect: libri_test_asr_anon
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/libri_test_asr_anon_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_libri_test_asr_anon
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_libri_test_asr_anon using the extractor in exp/models/asr_eval/extractor.
  decoding: libri_test_asr_anon
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_libri_test_asr_anon exp/models/asr_eval/graph_tgsmall data/libri_test_asr_anon_hires exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,3,15) and mean=7.5
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 9.17 [ 3214 / 35042, 270 ins, 426 del, 2518 sub ] exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall/wer_15_0.0
  rescoring: libri_test_asr_anon
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/libri_test_asr_anon_hires exp/models/asr_eval/decode_libri_test_asr_anon_tgsmall exp/models/asr_eval/decode_libri_test_asr_anon_tglarge
%WER 6.69 [ 2344 / 35042, 219 ins, 305 del, 1820 sub ] exp/models/asr_eval/decode_libri_test_asr_anon_tglarge/wer_15_0.5

Stage 13: Performing intelligibility assessment using ASR decoding on vctk...
  compute MFCC: vctk_dev_asr
utils/copy_data_dir.sh: copied data from data/vctk_dev_asr to data/vctk_dev_asr_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_dev_asr_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/vctk_dev_asr_hires
steps/make_mfcc.sh: moving data/vctk_dev_asr_hires/feats.scp to data/vctk_dev_asr_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_dev_asr_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_dev_asr_hires
steps/compute_cmvn_stats.sh data/vctk_dev_asr_hires
Succeeded creating CMVN stats for vctk_dev_asr_hires
fix_data_dir.sh: kept all 11372 utterances.
fix_data_dir.sh: old files are kept in data/vctk_dev_asr_hires/.backup
  compute i-vect: vctk_dev_asr
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/vctk_dev_asr_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_vctk_dev_asr
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_vctk_dev_asr using the extractor in exp/models/asr_eval/extractor.
  decoding: vctk_dev_asr
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_vctk_dev_asr exp/models/asr_eval/graph_tgsmall data/vctk_dev_asr_hires exp/models/asr_eval/decode_vctk_dev_asr_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_vctk_dev_asr_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_dev_asr_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,3,21) and mean=10.0
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_dev_asr_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 14.00 [ 12130 / 86627, 1150 ins, 1870 del, 9110 sub ] exp/models/asr_eval/decode_vctk_dev_asr_tgsmall/wer_15_0.0
  rescoring: vctk_dev_asr
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/vctk_dev_asr_hires exp/models/asr_eval/decode_vctk_dev_asr_tgsmall exp/models/asr_eval/decode_vctk_dev_asr_tglarge
%WER 10.79 [ 9351 / 86627, 995 ins, 1359 del, 6997 sub ] exp/models/asr_eval/decode_vctk_dev_asr_tglarge/wer_14_0.5

Stage 13: Performing intelligibility assessment using ASR decoding on vctk...
  compute MFCC: vctk_dev_asr_anon
utils/copy_data_dir.sh: copied data from data/vctk_dev_asr_anon to data/vctk_dev_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_dev_asr_anon_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/vctk_dev_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_dev_asr_anon_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_dev_asr_anon_hires
steps/compute_cmvn_stats.sh data/vctk_dev_asr_anon_hires
Succeeded creating CMVN stats for vctk_dev_asr_anon_hires
fix_data_dir.sh: kept all 11372 utterances.
fix_data_dir.sh: old files are kept in data/vctk_dev_asr_anon_hires/.backup
  compute i-vect: vctk_dev_asr_anon
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/vctk_dev_asr_anon_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_vctk_dev_asr_anon
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_vctk_dev_asr_anon using the extractor in exp/models/asr_eval/extractor.
  decoding: vctk_dev_asr_anon
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_vctk_dev_asr_anon exp/models/asr_eval/graph_tgsmall data/vctk_dev_asr_anon_hires exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,4,30) and mean=13.2
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 18.90 [ 16374 / 86627, 1479 ins, 2566 del, 12329 sub ] exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall/wer_16_0.0
  rescoring: vctk_dev_asr_anon
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/vctk_dev_asr_anon_hires exp/models/asr_eval/decode_vctk_dev_asr_anon_tgsmall exp/models/asr_eval/decode_vctk_dev_asr_anon_tglarge
%WER 15.32 [ 13269 / 86627, 1579 ins, 1729 del, 9961 sub ] exp/models/asr_eval/decode_vctk_dev_asr_anon_tglarge/wer_16_0.0

Stage 13: Performing intelligibility assessment using ASR decoding on vctk...
  compute MFCC: vctk_test_asr
utils/copy_data_dir.sh: copied data from data/vctk_test_asr to data/vctk_test_asr_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_asr_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/vctk_test_asr_hires
steps/make_mfcc.sh: moving data/vctk_test_asr_hires/feats.scp to data/vctk_test_asr_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_asr_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_asr_hires
steps/compute_cmvn_stats.sh data/vctk_test_asr_hires
Succeeded creating CMVN stats for vctk_test_asr_hires
fix_data_dir.sh: kept all 11448 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_asr_hires/.backup
  compute i-vect: vctk_test_asr
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/vctk_test_asr_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_vctk_test_asr
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_vctk_test_asr using the extractor in exp/models/asr_eval/extractor.
  decoding: vctk_test_asr
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_vctk_test_asr exp/models/asr_eval/graph_tgsmall data/vctk_test_asr_hires exp/models/asr_eval/decode_vctk_test_asr_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_vctk_test_asr_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_test_asr_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,3,26) and mean=11.4
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_test_asr_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 16.39 [ 14197 / 86642, 1325 ins, 2236 del, 10636 sub ] exp/models/asr_eval/decode_vctk_test_asr_tgsmall/wer_14_0.0
  rescoring: vctk_test_asr
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/vctk_test_asr_hires exp/models/asr_eval/decode_vctk_test_asr_tgsmall exp/models/asr_eval/decode_vctk_test_asr_tglarge
%WER 12.81 [ 11099 / 86642, 1300 ins, 1468 del, 8331 sub ] exp/models/asr_eval/decode_vctk_test_asr_tglarge/wer_14_0.0

Stage 13: Performing intelligibility assessment using ASR decoding on vctk...
  compute MFCC: vctk_test_asr_anon
utils/copy_data_dir.sh: copied data from data/vctk_test_asr_anon to data/vctk_test_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_asr_anon_hires
steps/make_mfcc.sh --nj 12 --cmd run.pl --mfcc-config conf/mfcc_hires.conf data/vctk_test_asr_anon_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/vctk_test_asr_anon_hires
steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_mfcc.sh: Succeeded creating MFCC features for vctk_test_asr_anon_hires
steps/compute_cmvn_stats.sh data/vctk_test_asr_anon_hires
Succeeded creating CMVN stats for vctk_test_asr_anon_hires
fix_data_dir.sh: kept all 11448 utterances.
fix_data_dir.sh: old files are kept in data/vctk_test_asr_anon_hires/.backup
  compute i-vect: vctk_test_asr_anon
steps/online/nnet2/extract_ivectors_online.sh --nj 12 --cmd run.pl data/vctk_test_asr_anon_hires exp/models/asr_eval/extractor exp/models/asr_eval/extractor/ivect_vctk_test_asr_anon
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/models/asr_eval/extractor/ivect_vctk_test_asr_anon using the extractor in exp/models/asr_eval/extractor.
  decoding: vctk_test_asr_anon
steps/nnet3/decode.sh --nj 12 --cmd run.pl --acwt 1.0 --post-decode-acwt 10.0 --online-ivector-dir exp/models/asr_eval/extractor/ivect_vctk_test_asr_anon exp/models/asr_eval/graph_tgsmall data/vctk_test_asr_anon_hires exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/models/asr_eval/graph_tgsmall exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,4,29) and mean=13.0
steps/diagnostic/analyze_lats.sh: see stats in exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall/log/analyze_lattice_depth_stats.log
score best paths
score confidence and timing with sclite
Decoding done.
%WER 18.90 [ 16379 / 86642, 1490 ins, 2660 del, 12229 sub ] exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall/wer_15_0.0
  rescoring: vctk_test_asr_anon
steps/lmrescore_const_arpa.sh --cmd run.pl exp/models/asr_eval/lang_test_tgsmall exp/models/asr_eval/lang_test_tglarge data/vctk_test_asr_anon_hires exp/models/asr_eval/decode_vctk_test_asr_anon_tgsmall exp/models/asr_eval/decode_vctk_test_asr_anon_tglarge
%WER 15.24 [ 13202 / 86642, 1289 ins, 2048 del, 9865 sub ] exp/models/asr_eval/decode_vctk_test_asr_anon_tglarge/wer_14_0.5

Stage 14: Collecting results
ASV-libri_dev_enrolls-libri_dev_trials_f
  EER: 8.807%
